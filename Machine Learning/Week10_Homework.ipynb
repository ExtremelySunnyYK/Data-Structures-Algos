{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Week 10 Problem Set\n",
    "\n",
    "## Homeworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW0.** Do the following before starting the homework questions.\n",
    "\n",
    "**Task 1.** Paste the following functions from your cohort sessions:\n",
    "- `get_features_target()`\n",
    "- `normalize_z()`\n",
    "- `normalize_minmax()`\n",
    "- `replace_target()`\n",
    "- `split_data()`\n",
    "- `prepare_feature()`\n",
    "- `prepare_target()`\n",
    "- `log_regression()`\n",
    "- `compute_cost_logreg()`\n",
    "- `gradient_descent_logreg()`\n",
    "- `predict_norm()`\n",
    "- `predict()`\n",
    "- `confusion_matrix()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_z(df):\n",
    "    dfout = (df - df.mean(axis=0)) / df.std(axis=0)\n",
    "    return dfout\n",
    "\n",
    "def get_features_targets(df, feature_names, target_names):\n",
    "    df_feature = df[feature_names]\n",
    "    df_target = df[target_names]\n",
    "    return df_feature, df_target\n",
    "\n",
    "def prepare_feature(df_feature): # creates X matrix\n",
    "    feature = df_feature.to_numpy()\n",
    "    array1 = np.ones((feature.shape[0], 1))\n",
    "#     array1 = np.ones(feature.shape) --> works too\n",
    "    X = np.concatenate((array1, feature), axis=1)\n",
    "    return X\n",
    "\n",
    "def prepare_target(df_target): # creates numpy array for y (target)\n",
    "    return df_target.to_numpy()\n",
    "\n",
    "def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n",
    "    # assuming that index is consistent between features and target\n",
    "    indices = df_target.index\n",
    "    if random_state != None:\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    # k is the no. of rows in the test set\n",
    "    num_rows = len(indices)\n",
    "    k = int(test_size * num_rows)\n",
    "    # randomly choose indices for test set\n",
    "    test_indices = np.random.choice(indices, k, replace=False)\n",
    "    \n",
    "    indices = set(indices)\n",
    "    test_indices = set(test_indices)\n",
    "    train_indices = indices - test_indices\n",
    "    \n",
    "    df_feature_train = df_feature.loc[train_indices, :]\n",
    "    df_feature_test = df_feature.loc[test_indices, :]\n",
    "    df_target_train = df_target.loc[train_indices, :]\n",
    "    df_target_test = df_target.loc[test_indices, :]\n",
    "\n",
    "    return df_feature_train, df_feature_test, df_target_train, df_target_test\n",
    " \n",
    "def replace_target(df_target, target_name, map_vals):\n",
    "    df_out = df_target.copy()\n",
    "    df_out.loc[:, target_name] = df_target[target_name].apply(lambda val: map_vals[val])\n",
    "    \n",
    "    return df_out    \n",
    "\n",
    "def normalize_minmax(dfin):\n",
    "\n",
    "    dfout = (dfin - dfin.min(axis=0))/(dfin.max(axis=0)-dfin.min(axis=0))\n",
    "            \n",
    "    return dfout\n",
    "\n",
    "def log_regression(beta, X):\n",
    "    z = np.matmul(X, beta)\n",
    "    hypothesis = 1 / (1 + np.exp(-z))\n",
    "    return hypothesis\n",
    "\n",
    "def compute_cost_logreg(beta, X, y):\n",
    "    np.seterr(divide = 'ignore') \n",
    "    p = log_regression(beta, X)\n",
    "    m = X.shape[0]\n",
    "    J = (-1 / m) * np.sum(np.where(y == 1, np.log(p), np.log(1 - p)))\n",
    "    np.seterr(divide = 'warn')\n",
    "    return J\n",
    "\n",
    "def gradient_descent_logreg(X, y, beta, alpha, num_iters):\n",
    "    m = X.shape[0]\n",
    "    J_storage = np.zeros(num_iters)\n",
    "    for n in range(num_iters):\n",
    "        p = log_regression(beta, X)\n",
    "        error = p - y\n",
    "        delta = np.matmul(X.T, error)\n",
    "        beta = beta - (alpha / m) * delta\n",
    "        # change the J value from 0 to sum cost (can also use an empty list and append to it)\n",
    "        J_storage[n] = compute_cost_logreg(beta, X, y)\n",
    "    return beta, J_storage\n",
    "\n",
    "def predict_norm(X, beta):\n",
    "    p = log_regression(beta, X)\n",
    "    return np.where(p >= 0.5, 1, 0)\n",
    "\n",
    "def predict(df_feature, beta):\n",
    "    feature_z = normalize_z(df_feature)\n",
    "    X = prepare_feature(feature_z)\n",
    "    return predict_norm(X, beta)\n",
    "  \n",
    "import itertools\n",
    "def confusion_matrix(ytrue, ypred, labels):\n",
    "    output = {i : 0 for i in list(itertools.product([0,1],repeat = 2))}\n",
    "    \n",
    "    for idx in range(ytrue.shape[0]):\n",
    "        actual = ytrue[idx,0]\n",
    "        pred = ypred[idx,0] # or using a list index ypred[idx][0]\n",
    "        output[(actual,pred)] +=1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Task 2.** Load the Iris data set from `iris_data.csv` into a Data Frame. \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read iris_data.csv\n",
    "df = pd.read_csv(\"iris_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Task 3.** Do the following tasks.\n",
    "\n",
    "- Read the following columns for the features: `'sepal_length', 'sepal_width', 'petal_length', 'petal_width'`.\n",
    "- Read the column `species` for the target.\n",
    "- Replace the `species` column with the following mapping:\n",
    "    - `Iris-setosa`: `0`\n",
    "    - `Iris-versicolor`: `1`\n",
    "    - `Iris-virginica`: `2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica':2}\n",
    "\n",
    "# extract the features and the target\n",
    "df_features, df_target = get_features_targets(df, columns, [\"species\"])\n",
    "\n",
    "# replace the target using the mapping\n",
    "df_target = replace_target(df_target, \"species\", mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw01",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "result = np.unique(df_target['species'], return_counts=True)\n",
    "assert (result[0] == [0, 1, 2]).all()\n",
    "assert (result[1] == [50, 50, 50]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW1.** *One-vs-All target:* Write a function that takes in a target data frame and returns a new dataframe where the size of the column is the same as the number of category. The function makes use of `replace_target()` function to create one-vs-all target values. \n",
    "\n",
    "For example, if we have three categories of class, the columns of the returned data frame will be as follows:\n",
    "- column target: this is the original target column\n",
    "- column 0: the target with values of 0 will be set to 1 while the rest will be replaced with 0.\n",
    "- column 1: the target with values of 1 will be set to 1 while the rest will be replaced with 0.\n",
    "- column 2: the target with values of 2 will be set to 1 while while the rest will be replaced with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfut[1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     species  1\n",
       "0          0  1\n",
       "1          0  1\n",
       "2          0  1\n",
       "3          0  1\n",
       "4          0  1\n",
       "..       ... ..\n",
       "145        2  1\n",
       "146        2  1\n",
       "147        2  1\n",
       "148        2  1\n",
       "149        2  1\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_onevsall_columns(df_target, col):\n",
    "    dfout = df_target.copy()\n",
    "    num_classes = df_target[col].nunique()\n",
    "    for i in range(num_classes):\n",
    "        dfout[i] = dfout[col].apply(lambda y : np.where(y == i,1,0))\n",
    "    \n",
    "    return dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw11",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     species  0  1  2\n",
      "0          0  1  0  0\n",
      "1          0  1  0  0\n",
      "2          0  1  0  0\n",
      "3          0  1  0  0\n",
      "4          0  1  0  0\n",
      "..       ... .. .. ..\n",
      "145        2  0  0  1\n",
      "146        2  0  0  1\n",
      "147        2  0  0  1\n",
      "148        2  0  0  1\n",
      "149        2  0  0  1\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_targets = create_onevsall_columns(df_target, 'species')\n",
    "print(df_targets)\n",
    "result = np.unique(df_targets['species'], return_counts=True)\n",
    "assert (result[0] == [0, 1, 2]).all()\n",
    "assert (result[1] == [50, 50, 50]).all()\n",
    "result = np.unique(df_targets[0], return_counts=True)\n",
    "assert (result[0] == [0, 1]).all()\n",
    "assert (result[1] == [100, 50]).all()\n",
    "result = np.unique(df_targets[1], return_counts=True)\n",
    "assert (result[0] == [0, 1]).all()\n",
    "assert (result[1] == [100, 50]).all()\n",
    "result = np.unique(df_targets[2], return_counts=True)\n",
    "assert (result[0] == [0, 1]).all()\n",
    "assert (result[1] == [100, 50]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW2.** *Multiple features and splitting of data set:* Do the following task in the code below:\n",
    "- Read the following columns for the features: `sepal_length`,`sepal_width`, `petal_length`, `petal_width` normalize it using `normalize_z()`. \n",
    "- Read `species` as the target column and use `create_onevsall_columns()` to create the additional target columns to do multi class classification.\n",
    "- Split the data set with 30% test size and `random_state = 100`.\n",
    "- Normalize the training feature data set using `normalize_z()` function.\n",
    "- Convert to numpy array both the target and the features using `prepare_feature()` and `prepare_target()` functions.\n",
    "- Call `gradient_descent()` function to get the parameters using the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica':2}\n",
    "\n",
    "# extract the features and the target\n",
    "df_features, df_target = get_features_targets(df, columns, [\"species\"])\n",
    "\n",
    "# change target values to integer using mapping\n",
    "df_target = replace_target(df_target, \"species\", mapping)\n",
    "\n",
    "# create one vs all columns for the target\n",
    "df_targets = create_onevsall_columns(df_target, 'species')\n",
    "\n",
    "# split the data using random_state = 100 and 30% test size\n",
    "df_features_train, df_features_test, df_targets_train, df_targets_test = split_data(df_features, df_targets, test_size = 0.3, random_state = 100)\n",
    "\n",
    "# normalize the training feature\n",
    "df_features_train_z = normalize_z(df_features_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw21",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_features_train_z.shape == (105, 4)\n",
    "\n",
    "assert np.isclose(df_features_train_z.min(), -2.52349).any()\n",
    "assert np.isclose(df_features_train_z.max(), 2.73284).any()\n",
    "assert np.isclose(df_features_train_z['sepal_width'].mean(), 0)\n",
    "assert np.isclose(df_features_train_z['sepal_width'].std(), 1, atol=0.01)\n",
    "\n",
    "assert (np.unique(df_targets_train['species']) == [0, 1, 2]).all()\n",
    "assert (np.unique(df_targets_train[0]) == [0, 1]).all()\n",
    "assert (np.unique(df_targets_train[1]) == [0, 1]).all()\n",
    "assert (np.unique(df_targets_train[2]) == [0, 1]).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW3.** *Build Multi-class Model:* Write a function `build_model_multiclass()` which takes in the following arguments:\n",
    "- `df_features`: which is a Pandas data framecontaining the features.\n",
    "- `df_targets`: which is a Pandas data frame containing the target for one vs all classification. \n",
    "- `col_target`: the name of the column target in the original data frame which is also the key of the dictionary containing the original target numpy array.\n",
    "- `iterations`: the number of iterations to perform the gradient descent. By default it is set to 1500.\n",
    "- `alpha`: the learning rate in the gradient descent algorithm. By default it is set to 0.01.\n",
    "\n",
    "The function should return a dictionary of dictionary. The output dictionary has the following key and values:\n",
    "- key: the keys are the categories or the labels in the target.\n",
    "- values: the values are another dictionary for that particular label. This dictionary has two keys: `beta` and `J_storage`, which gives the parameter value for that particular label and its cost minimization values at every iteration.\n",
    "\n",
    "Hint:\n",
    "- you need to call `prepare_feature()` and `prepare_target()` to change the Pandas data frame to Numpy arrays.\n",
    "- in order to create a data frame instead of a series when accessing a column, use `df[[c]]` (will output data frame) instead of `df[c]` (will output series). \n",
    "- You need to use `normalize_minmax()` on your target before passing it on to `gradient_descent_logreg()` because the function logistic regression has the normalized value of 0 to 1 in the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_multiclass(df_features, df_targets, col_target, iterations=1500, alpha=0.01):\n",
    "    output = {}\n",
    "    \n",
    "    # change the feature columns to numpy array and append column of 1s\n",
    "    features = prepare_feature(df_features)\n",
    "    \n",
    "    # change the target column to numpy array\n",
    "    target = prepare_target(df_targets[[col_target]])\n",
    "    \n",
    "    target = normalize_minmax(target)\n",
    "    \n",
    "    # provide initial guess for theta\n",
    "    beta = np.zeros((features.shape[1],1))\n",
    "\n",
    "    # call the gradient descent method\n",
    "    beta, J_storage = gradient_descent_logreg(features, target, beta, alpha, iterations)\n",
    "    \n",
    "    \n",
    "    output[\"beta\"] = beta\n",
    "    output[\"J_storage\"] = J_storage\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = build_model_multiclass(df_features_train_z, df_targets_train, 'species')\n",
    "\n",
    "# assert isinstance(output, dict)\n",
    "# expected = np.array([[ -1.0198841], [ -0.69883077], [  1.0774116], [-1.17170999], [-1.12846826]])\n",
    "# assert np.isclose(output[0]['beta'], expected).all()\n",
    "# expected = np.array([[ -0.63304937], [ 0.11684857], [-1.15346071], [ 0.18746937], [-0.14534827 ]])\n",
    "# assert np.isclose(output[1]['beta'], expected).all()\n",
    "# expected = np.array([[-1.31740148 ], [0.42271871], [0.18526839], [ 0.8831822], [1.17929455]])\n",
    "# assert np.isclose(output[2]['beta'], expected).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta': array([[-0.29399691],\n",
       "        [ 0.45020182],\n",
       "        [-0.35705062],\n",
       "        [ 0.91017137],\n",
       "        [ 1.04886677]]),\n",
       " 'J_storage': array([0.68983131, 0.68656695, 0.68335332, ..., 0.42525331, 0.42522814,\n",
       "        0.42520297])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw31",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8e31c71c3c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0198841\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.69883077\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m  \u001b[0;36m1.0774116\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.17170999\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.12846826\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.63304937\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;36m0.11684857\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.15346071\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;36m0.18746937\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.14534827\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "output = build_model_multiclass(df_features_train_z, df_targets_train, 'species')\n",
    "\n",
    "assert isinstance(output, dict)\n",
    "expected = np.array([[ -1.0198841], [ -0.69883077], [  1.0774116], [-1.17170999], [-1.12846826]])\n",
    "assert np.isclose(output[0]['beta'], expected).all()\n",
    "expected = np.array([[ -0.63304937], [ 0.11684857], [-1.15346071], [ 0.18746937], [-0.14534827 ]])\n",
    "assert np.isclose(output[1]['beta'], expected).all()\n",
    "expected = np.array([[-1.31740148 ], [0.42271871], [0.18526839], [ 0.8831822], [1.17929455]])\n",
    "assert np.isclose(output[2]['beta'], expected).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(output), 1)\n",
    "idx = 0\n",
    "for c in output:\n",
    "    print(f'class model = {c:}', output[c]['beta'])\n",
    "    axes[idx].plot(output[c]['J_storage'])\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW4.** *Predict Multi-class:* Write a function `predict_multiclass()` that takes in the data frame for the features and the parameters for the multi-class classification and return a Numpy array for the predicted target.\n",
    "\n",
    "Recall that you need to do the following steps:\n",
    "- Normalize the features and change to numpy array\n",
    "- For each of the class, calculate the probability by using `log_regression()` function.\n",
    "- For each record, find the class that gives the maximum probability.\n",
    "- Returns a Numpy array with the predicted target values\n",
    "\n",
    "You can use the following function in your code:\n",
    "- `np.argmax()` to find the column name with the maximum value\n",
    "- `df.apply(func, axis=1)`: which is to apply some function on a particular axis. Setting axis=1 means that the function is to be applied accross the columns of the data frame instead of the index or the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_multiclass(df_features, multi_beta):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw41",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pred = predict_multiclass(df_features_test, output)\n",
    "\n",
    "assert isinstance(pred, np.ndarray)\n",
    "assert pred.shape == (45, 1)\n",
    "assert pred.min() == 0\n",
    "assert pred.max() == 2\n",
    "assert np.median(pred) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test['sepal_length'], df_targets_test['species'])\n",
    "plt.scatter(df_features_test['sepal_length'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test['sepal_width'], df_targets_test['species'])\n",
    "plt.scatter(df_features_test['sepal_width'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test['petal_length'], df_targets_test['species'])\n",
    "plt.scatter(df_features_test['petal_length'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test['petal_width'], df_targets_test['species'])\n",
    "plt.scatter(df_features_test['petal_width'], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW5.** *Confusion Matrix:* Write a function to calculate the confusion matrix for multi-class label. If you write the solution in the Cohort session properly, the solution will be the same as in the Cohort session.\n",
    "\n",
    "Make sure that you can output a dictionary where the keys are all the combinations of all the classes: `(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def confusion_matrix(ytrue, ypred, labels):\n",
    "    output = {}\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw51",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_targets_test.values, pred, [0, 1, 2])\n",
    "print(cm)\n",
    "assert cm == {(0, 0): 16, (0, 1): 0, (0, 2): 0, (1, 0): 0, (1, 1): 9, (1, 2): 2, (2, 0): 0, (2, 1): 3, (2, 2): 15}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW6.** *Metrics:* Write a function `calc_accuracy()` that takes in a Confusion Matrix array and output a dictionary with the following keys and values:\n",
    "- `accuracy`: total number of correct predictions / total number of records\n",
    "- `sensitivity`: total correct positive cases / total positive cases\n",
    "- `precision`: total  of correct positive cases / total predicted positive cases\n",
    "\n",
    "For multiple classes, we can also calculate *sensitivity* and *precision* for each of the class. For example, to calculate the sensitivity for class *i*, we use:\n",
    "\n",
    "$$\\text{sensitivity}_i = \\frac{M_{ii}}{\\sum_j{M_{ij}}}$$\n",
    "\n",
    "This means that we get the value at row *i* and columnn *i* which is the total correct case for class *i* and the sum over all the columns in row *i* which is the total cases for class *i*. \n",
    "\n",
    "Similarly, we can calculate the precision for class *i* using:\n",
    "\n",
    "$$\\text{precision}_i = \\frac{M_{ii}}{\\sum_j{M_{ji}}}$$\n",
    "\n",
    "**Notice that the indices are swapped for the denominator**. For precision, we instead of summing over all the columns, we sum over all the rows in column *i* which is the total cases when class *i* is *predicted*.\n",
    "\n",
    "The output is a dictionary with one of the keys called `accuracy` and the rest of the keys are the label for the different classes, i.e. 0, 1, and 2 in our example here. The value for `accuracy` key is a float. On the other hand, the values for the other label keys is another dictionary that has `sensitivity` and `precision` as the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(cm, labels):\n",
    "    output = {'accuracy': 0}\n",
    "    for l in labels:\n",
    "        output[l] = {}\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw61",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "metrics = calc_accuracy(cm, [0,1,2])\n",
    "print(metrics)\n",
    "assert np.isclose(metrics['accuracy'], 0.88888)\n",
    "assert metrics[0] == {'sensitivity': 1.0, 'precision': 1.0}\n",
    "assert np.isclose(metrics[0]['sensitivity'], 1.0)\n",
    "assert np.isclose(metrics[0]['precision'], 1.0)\n",
    "assert np.isclose(metrics[1]['sensitivity'], 0.8181818)\n",
    "assert np.isclose(metrics[1]['precision'], 0.75)\n",
    "assert np.isclose(metrics[2]['sensitivity'], 0.833333)\n",
    "assert np.isclose(metrics[2]['precision'], 0.88235)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW7.** *Optional:* Redo the above tasks using Scikit Learn libraries. You will need to use the following:\n",
    "- [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "\n",
    "You can refer to the followign discussion on the different minimization solver for `LogisticRegression()` class.\n",
    "- [Stack overflow - logistic regression python solvers' defintions](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica':2}\n",
    "\n",
    "# get the features and the columns\n",
    "df_features = None\n",
    "\n",
    "# replace target values with integers using the mapping\n",
    "df_target = None\n",
    "\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data set using random_state = 100 and 30% test size\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = None, None, None, None\n",
    "\n",
    "# change feature to numpy array and append column of 1s\n",
    "feature = None\n",
    "\n",
    "# change target to numpy array\n",
    "target = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create LogisticRegression object instance\n",
    "# set solver to 'newton-cg' and multi_class to 'auto'\n",
    "model = None\n",
    "\n",
    "# build model\n",
    "pass\n",
    "\n",
    "# get predicted value\n",
    "pred = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate confusion matrix\n",
    "cm = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected = np.array([[16,  0,  0], [ 0, 11,  0], [ 0,  1, 17]])\n",
    "assert (cm == expected).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"sepal_width\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"sepal_width\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"sepal_length\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"sepal_length\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"petal_width\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"petal_width\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"petal_length\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"petal_length\"], pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.7]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
